{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please Open this Notebook in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/11ko0DBnI1QLxVoJQR8gt9b4JDcvbCrtU)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "CWrRz3kXDksW"
   },
   "source": [
    "gun_detection\n",
    "\n",
    "├─ data\n",
    "│   ├── images\n",
    "│   │   ├── armas (1).jpg\n",
    "│   │   ├── armas (2).jpg\n",
    "│   │   └── ...\n",
    "│   ├── train_labels\n",
    "│   │   ├── armas (1).xml\n",
    "│   │   ├── armas (2).xml\n",
    "│   │   └── ...\n",
    "│   ├── test_labels\n",
    "│   │   ├── armas (10).xml\n",
    "│   │   ├── armas (20).xml\n",
    "│   │   └── ...\n",
    "│   ├── label_map.pbtxt\n",
    "│   ├── test_labels.csv\n",
    "│   ├── train_labels.csv\n",
    "│   ├── test_labels.record\n",
    "│   └── train_labels.record\n",
    "├─ models\n",
    "│   ├─ official\n",
    "│   ├─ research\n",
    "│   │   ├── object_detection\n",
    "│   │   ├── training\n",
    "│   │   └─ ...\n",
    "│   ├─ samples\n",
    "│   └─ tutorials\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMlXJ2yIV8e7"
   },
   "source": [
    "## Choosing a pre training model\n",
    "The model used for this project is `ssd_mobilenet_v2_coco`.\n",
    "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
    "\n",
    "Because the interestes of this project is to interfere on real time video, i am chose a model that has highest inference speed `(ms)` and the highest `mAP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3_Ns54i3HgO"
   },
   "outputs": [],
   "source": [
    "# Number of training steps.\n",
    "num_steps = 200_000 # 1_000\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 50\n",
    "\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "\n",
    "# Some models to train on\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv3Zm042QGJy"
   },
   "source": [
    "## Installing Required Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68StUELaQPS2"
   },
   "outputs": [],
   "source": [
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -qq pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERyocH9U-o2Y"
   },
   "source": [
    "## General imports\n",
    "Other Imports will be done after downloading some packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "CEVLeKXh-s23",
    "outputId": "6816c7a8-b157-4831-e31e-8790f2d7afaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import io\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOcbTFEiPBKA"
   },
   "source": [
    "## Downloading and Orgniazing Images and Annotations\n",
    "1. Downloading the images and annotations from the source and unzip them\n",
    "2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n",
    "3. Creating two directories; for training and testing labels\n",
    "4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QY-CyUQwyZr"
   },
   "outputs": [],
   "source": [
    "#creates a directory for the whole project\n",
    "!mkdir gun_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "CHPQQmhm7RLe",
    "outputId": "1aaf4f3e-e072-4fb4-8706-53cd768c5071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection\n"
     ]
    }
   ],
   "source": [
    "cd gun_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "Tp62o3a07UbP",
    "outputId": "dbba34fd-84b5-4af4-d9d4-a6581771b259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-05 01:50:13--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
      "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
      "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 250005059 (238M) [application/zip]\n",
      "Saving to: ‘WeaponS.zip’\n",
      "\n",
      "WeaponS.zip         100%[===================>] 238.42M  11.2MB/s    in 22s     \n",
      "\n",
      "2019-12-05 01:50:35 (10.9 MB/s) - ‘WeaponS.zip’ saved [250005059/250005059]\n",
      "\n",
      "--2019-12-05 01:50:39--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
      "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
      "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1420022 (1.4M) [application/zip]\n",
      "Saving to: ‘WeaponS_bbox.zip’\n",
      "\n",
      "WeaponS_bbox.zip    100%[===================>]   1.35M  4.88MB/s    in 0.3s    \n",
      "\n",
      "2019-12-05 01:50:40 (4.88 MB/s) - ‘WeaponS_bbox.zip’ saved [1420022/1420022]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training images and annotations\n",
    "\n",
    "#Source: https://sci2s.ugr.es/weapons-detection\n",
    "\n",
    "\n",
    "#download the images zip\n",
    "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
    "\n",
    "#unzip the image file\n",
    "!unzip -q WeaponS.zip\n",
    "\n",
    "#download the annotations zip\n",
    "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
    "\n",
    "#unzip the annotations file\n",
    "!unzip -q WeaponS_bbox.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0czMMeR8GxW"
   },
   "outputs": [],
   "source": [
    "# creating a directory to store the training and testing data\n",
    "!mkdir data\n",
    "\n",
    "# folders for the training and testing data.\n",
    "!mkdir data/images data/train_labels data/test_labels\n",
    "\n",
    "\n",
    "# combining the images and annotation in the training folder:\n",
    "# moves the images to data folder\n",
    "!mv WeaponS/* data/images\n",
    "\n",
    "# moves the annotations to data folder\n",
    "!mv WeaponS_bbox/* data/train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vv8pmB2D80M7"
   },
   "outputs": [],
   "source": [
    "# (Optional) deleting the zipped and unzipped folders \n",
    "!rm -rf WeaponS_bbox.zip  WeaponS.zip WeaponS/  WeaponS_bbox/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUl-XRwPvj4j"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shuffles the labels folder in random order (not really random, by their hash value instead)\n",
    "# Moves the fiest 600 labels to the testing dir: `test_labels`\n",
    "!ls data/train_labels/* | sort -R | head -600 | xargs -I{} mv {} data/test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "pmvDu-rUHz96",
    "outputId": "dcf5ccfb-90a5-4cf5-846c-28748ba38e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "# 2400 \"images\"(xml) for training\n",
    "ls -1 data/train_labels/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "K8y-1_t7wRJc",
    "outputId": "158ed4af-07af-4044-d184-98f0a1f3b623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "# 600 \"images\"(xml) for testing\n",
    "ls -1 data/test_labels/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOfuwfPrPSMz"
   },
   "source": [
    "## Preprocessing Images and Labels\n",
    "1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n",
    "2. Creating a pbtxt file that specifies the number of class (one in this case)\n",
    "3. Checking if the annotations for each object are placed within the range of the image width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "TBHBFpWyEIDI",
    "outputId": "49b00cad-c5cd-40ad-e00e-208e9892a1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection/data\n",
      "Successfully converted train_labels xml to csv.\n",
      "Successfully converted test_labels xml to csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
    "\n",
    "#converts the annotations/labels into one csv file for each training and testing labels\n",
    "#creats label_map.pbtxt file\n",
    "\n",
    "%cd /content/gun_detection/data\n",
    "\n",
    "\n",
    "# images extension\n",
    "images_extension = 'jpg'\n",
    "\n",
    "# takes the path of a directory that contains xml files and converts\n",
    "#  them to one csv file.\n",
    "\n",
    "# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n",
    "# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n",
    "def xml_to_csv(path):\n",
    "  classes_names = []\n",
    "  xml_list = []\n",
    "\n",
    "  for xml_file in glob.glob(path + '/*.xml'):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for member in root.findall('object'):\n",
    "      classes_names.append(member[0].text)\n",
    "      value = (root.find('filename').text + '.' + images_extension,\n",
    "               int(root.find('size')[0].text),\n",
    "               int(root.find('size')[1].text),\n",
    "               member[0].text,\n",
    "               int(member[4][0].text),\n",
    "               int(member[4][1].text),\n",
    "               int(member[4][2].text),\n",
    "               int(member[4][3].text))\n",
    "      xml_list.append(value)\n",
    "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
    "  classes_names = list(set(classes_names))\n",
    "  classes_names.sort()\n",
    "  return xml_df, classes_names\n",
    "\n",
    "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
    "for label_path in ['train_labels', 'test_labels']:\n",
    "  image_path = os.path.join(os.getcwd(), label_path)\n",
    "  xml_df, classes = xml_to_csv(label_path)\n",
    "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
    "  print(f'Successfully converted {label_path} xml to csv.')\n",
    "\n",
    "# Creating the `label_map.pbtxt` file\n",
    "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
    "\n",
    "pbtxt_content = \"\"\n",
    "\n",
    "#creats a pbtxt file the has the class names.\n",
    "for i, class_name in enumerate(classes):\n",
    "    # display_name is optional.\n",
    "    pbtxt_content = (\n",
    "        pbtxt_content\n",
    "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Gun'\\n }}\\n\\n\".format(i + 1, class_name)\n",
    "    )\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write(pbtxt_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "rtfjZcD-CCdM",
    "outputId": "ccdabe00-5228-4f5d-88d2-6437913b29d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "    id: 1\n",
      "    name: 'pistol'\n",
      "    display_name: 'Gun'\n",
      " }"
     ]
    }
   ],
   "source": [
    "#checking the pbtxt file\n",
    "!cat label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "yP8gohagKFXn",
    "outputId": "7a04d81d-94f6-4159-ad18-c1fb232f1643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mimages\u001b[0m/          \u001b[01;34mtest_labels\u001b[0m/     \u001b[01;34mtrain_labels\u001b[0m/\n",
      "label_map.pbtxt  test_labels.csv  train_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# They are there!\n",
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "L4p7J6mFLLZf",
    "outputId": "164806df-b217-4197-c891-9aaaa54afa1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: train_labels.csv\n",
      "XMIN > org_width for file armas (2815).jpg\n",
      "XMAX > org_width for file armas (2815).jpg\n",
      "YMIN > org_height for file armas (2815).jpg\n",
      "YMAX > org_height for file armas (2815).jpg\n",
      "Error for file: armas (2815).jpg\n",
      "\n",
      "Checked 2770 files and realized 1 errors\n",
      "Checking file: test_labels.csv\n",
      "Checked 694 files and realized 0 errors\n"
     ]
    }
   ],
   "source": [
    "#checks if the images box position is placed within the image.\n",
    "\n",
    "#note: while this doesn't checks if the boxes/annotatoins are correctly\n",
    "# placed around the object, Tensorflow will through an error if this occured.\n",
    "\n",
    "# path to images\n",
    "images_path = 'images'\n",
    "\n",
    "#loops over both train_labels and test_labels csv files to do the check\n",
    "# returns the image name where an error is found \n",
    "# return the incorrect attributes; xmin, ymin, xmax, ymax.\n",
    "for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n",
    "  with open(CSV_FILE, 'r') as fid:  \n",
    "      print('Checking file:', CSV_FILE) \n",
    "      file = csv.reader(fid, delimiter=',')\n",
    "      first = True \n",
    "      cnt = 0\n",
    "      error_cnt = 0\n",
    "      error = False\n",
    "      for row in file:\n",
    "          if error == True:\n",
    "              error_cnt += 1\n",
    "              error = False         \n",
    "          if first == True:\n",
    "              first = False\n",
    "              continue     \n",
    "          cnt += 1      \n",
    "          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n",
    "          path = os.path.join(images_path, name)\n",
    "          img = cv2.imread(path)         \n",
    "          if type(img) == type(None):\n",
    "              error = True\n",
    "              print('Could not read image', img)\n",
    "              continue     \n",
    "          org_height, org_width = img.shape[:2]     \n",
    "          if org_width != width:\n",
    "              error = True\n",
    "              print('Width mismatch for image: ', name, width, '!=', org_width)     \n",
    "          if org_height != height:\n",
    "              error = True\n",
    "              print('Height mismatch for image: ', name, height, '!=', org_height) \n",
    "          if xmin > org_width:\n",
    "              error = True\n",
    "              print('XMIN > org_width for file', name)  \n",
    "          if xmax > org_width:\n",
    "              error = True\n",
    "              print('XMAX > org_width for file', name)\n",
    "          if ymin > org_height:\n",
    "              error = True\n",
    "              print('YMIN > org_height for file', name)\n",
    "          if ymax > org_height:\n",
    "              error = True\n",
    "              print('YMAX > org_height for file', name)\n",
    "          if error == True:\n",
    "              print('Error for file: %s' % name)\n",
    "              print()\n",
    "      print('Checked %d files and realized %d errors' % (cnt, error_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vD5luKTsMx7F"
   },
   "outputs": [],
   "source": [
    "#we have only one image with incoorect box position, we could just remove it \n",
    "#removing the image \n",
    "rm images/'armas (2815).jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ze4z9bW3ZjhC"
   },
   "outputs": [],
   "source": [
    "#removing the xml for that image as well\n",
    "\n",
    "#reading the gun_labels df\n",
    "df = pd.read_csv('/content/gun_detection/data/test_labels.csv')\n",
    "# removing armas (2815).jpg\n",
    "df = df[df['filename'] != 'armas (2815).jpg']\n",
    "\n",
    "#reseting the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#saving the df\n",
    "df.to_csv('/content/gun_detection/data/test_labels.csv')\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/gun_detection/data/train_labels.csv')\n",
    "# removing armas (2815).jpg\n",
    "df = df[df['filename'] != 'armas (2815).jpg']\n",
    "\n",
    "#reseting the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#saving the df\n",
    "df.to_csv('/content/gun_detection/data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_tyvKnBP6qD"
   },
   "source": [
    "## Downloading and Preparing Tensorflow model\n",
    "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n",
    "2. Adding scripts to the os environment.\n",
    "3. Testing the model builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "IIxz1GqJQA3f",
    "outputId": "2de9b87e-fcfd-402d-db15-a2190460f9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection\n"
     ]
    }
   ],
   "source": [
    "# Downlaods Tenorflow\n",
    "%cd /content/gun_detection/\n",
    "!git clone --q https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "tjcAhsxRQ5N1",
    "outputId": "95f16837-dd58-436d-e4b7-16f5e2f3d6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /content/gun_detection/models/research\n",
    "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# exports the PYTHONPATH environment variable with the reasearch and slim paths\n",
    "os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "3bMNsrwTSJi2",
    "outputId": "9179a909-ef56-4a18-bd17-4fc526bbe601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /content/gun_detection/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gun_detection/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Running tests under Python 3.6.9: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
      "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 17 tests in 0.180s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# testing the model builder\n",
    "!python3 object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9C3L_r4Pi6m"
   },
   "source": [
    "## Generating Tf record\n",
    "- Generating two TFRecords files for the training and testing CSVs.\n",
    "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "nK2unk-9LB_E",
    "outputId": "25de6072-48e1-4ef0-dd5d-495b63458bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection/models\n",
      "Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n",
      "Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"
     ]
    }
   ],
   "source": [
    "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
    "\n",
    "# converts the csv files for training and testing data to two TFRecords files.\n",
    "# places the output in the same directory as the input\n",
    "\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "%cd /content/gun_detection/models/\n",
    "\n",
    "data_base_url = '/content/gun_detection/data/'\n",
    "image_dir = data_base_url +'images/'\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "\t\tif row_label == 'pistol':\n",
    "\t\t\t\treturn 1\n",
    "\t\telse:\n",
    "\t\t\t\tNone\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
    "\t\tgb = df.groupby(group)\n",
    "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "\t\twith tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "\t\t\t\tencoded_jpg = fid.read()\n",
    "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "\t\timage = Image.open(encoded_jpg_io)\n",
    "\t\twidth, height = image.size\n",
    "\n",
    "\t\tfilename = group.filename.encode('utf8')\n",
    "\t\timage_format = b'jpg'\n",
    "\t\txmins = []\n",
    "\t\txmaxs = []\n",
    "\t\tymins = []\n",
    "\t\tymaxs = []\n",
    "\t\tclasses_text = []\n",
    "\t\tclasses = []\n",
    "\n",
    "\t\tfor index, row in group.object.iterrows():\n",
    "\t\t\t\txmins.append(row['xmin'] / width)\n",
    "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
    "\t\t\t\tymins.append(row['ymin'] / height)\n",
    "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
    "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
    "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
    "\n",
    "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
    "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
    "\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
    "\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
    "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
    "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "\t\t}))\n",
    "\t\treturn tf_example\n",
    "\n",
    "for csv in ['train_labels', 'test_labels']:\n",
    "  writer = tf.python_io.TFRecordWriter(data_base_url + csv + '.record')\n",
    "  path = os.path.join(image_dir)\n",
    "  examples = pd.read_csv(data_base_url + csv + '.csv')\n",
    "  grouped = split(examples, 'filename')\n",
    "  for group in grouped:\n",
    "      tf_example = create_tf_example(group, path)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "  writer.close()\n",
    "  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n",
    "  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "i1zRJducWs-X",
    "outputId": "5c78a336-9b47-4e6d-a333-b38c8df81130"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/gun_detection/models/research'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFRecords are created\n",
    "ls -l ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVYx03PY94RN"
   },
   "outputs": [],
   "source": [
    "#setting the paths for the records and pbtx for easier access later.\n",
    "test_record_fname = '/content/gun_detection/data/test_labels.record'\n",
    "train_record_fname = '/content/gun_detection/data/train_labels.record'\n",
    "label_map_pbtxt_fname = '/content/gun_detection/data/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMckMSJqFMyc"
   },
   "source": [
    "## Downloading the Base Model\n",
    "1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n",
    "2. Creating a dir to save the model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "UvN9Cw65FQzB",
    "outputId": "c662b504-ecbb-4f92-da6a-e625748c9c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /content/gun_detection/models/research\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
    "\n",
    "\n",
    "#selecting the model\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "\n",
    "#creating the downlaod link for the model selected\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "#the distination folder where the model will be saved\n",
    "DEST_DIR = '/content/gun_detection/models/research/pretrained_model'\n",
    "\n",
    "#checks if the model has already been downloaded\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#unzipping the file and extracting its content\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# creating an output file to save the model while training\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "pbjXKVMmFk47",
    "outputId": "94f90772-6f3c-4372-ce84-890f3e8c0296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gun_detection/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
      "drwxr-xr-x 70 root   root  4.0K Dec  5 01:52 ..\n",
      "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
      "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
      "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
     ]
    }
   ],
   "source": [
    "#checking the content of the model\n",
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Q4j-nF6gFnie",
    "outputId": "a784a137-c1bf-494d-a371-44fcff214d51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/gun_detection/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the actual model file name\n",
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnjQgJZiGAcA"
   },
   "source": [
    "## Configuring the Training Pipeline\n",
    "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
    "2. Adding some Image augmentation.\n",
    "3. Creating a directory to save the model at each checkpoint while training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esT23QLsGEk0"
   },
   "outputs": [],
   "source": [
    "# the path for the configuration file to be edited \n",
    "config_path = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n",
    "\n",
    "# adding the config path with the pretrained model name selected\n",
    "pipeline_fname = os.path.join(config_path, pipeline_file)\n",
    "\n",
    "#checks if the files name is correct and does exist\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MS_EnzwHGVtY"
   },
   "outputs": [],
   "source": [
    "# Use this if you dont know how many classes you have.\n",
    "# returns the number of classes found in the pbtxt file created above\n",
    "\n",
    "# we have only one class here, so its not needed\n",
    "\n",
    "# def get_num_classes(pbtxt_fname):\n",
    "#     from object_detection.utils import label_map_util\n",
    "#     label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "#     categories = label_map_util.convert_label_map_to_categories(\n",
    "#         label_map, max_num_classes=90, use_display_name=True)\n",
    "#     category_index = label_map_util.create_category_index(categories)\n",
    "#     return len(category_index.keys())\n",
    "\n",
    "# num_classes = get_num_classes(label_map_pbtxt_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Kfsl5CsDGY3-",
    "outputId": "ee6c1893-8d38-4b88-e262-a6262dd87b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
     ]
    }
   ],
   "source": [
    "#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n",
    "# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n",
    "# Check this link to add more: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
    "\n",
    "%%writefile /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 1\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }\n",
    "    }\n",
    "    image_resizer {\n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: true\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        conv_hyperparams {\n",
    "          activation: RELU_6,\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "            weight: 0.001\n",
    "          }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              stddev: 0.03\n",
    "              mean: 0.0\n",
    "            }\n",
    "          }\n",
    "          batch_norm {\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'ssd_mobilenet_v2'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1.0\n",
    "      conv_hyperparams {\n",
    "        activation: RELU_6,\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 0.001\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }\n",
    "        }\n",
    "        batch_norm {\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    loss {\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "        }\n",
    "      }\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000\n",
    "        iou_threshold: 0.95\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 3\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 15\n",
    "        max_total_detections: 15\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 12\n",
    "  optimizer {\n",
    "    rms_prop_optimizer: {\n",
    "      learning_rate: {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.003\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.95\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "      decay: 0.9\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "\n",
    "  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n",
    "  fine_tune_checkpoint_type:  \"detection\"\n",
    "  # Note: The below line limits the training process to 200K steps, which we\n",
    "  # empirically found to be sufficient enough to train the pets dataset. This\n",
    "  # effectively bypasses the learning rate schedule (the learning rate will\n",
    "  # never decay). Remove the below line to train indefinitely.\n",
    "  num_steps: 200000\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_adjust_contrast {\n",
    "    }\n",
    "  }\n",
    "\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/gun_detection/data/train_labels.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  num_examples: 599\n",
    "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "  # Remove the below line to evaluate indefinitely.\n",
    "  #max_evals: 10\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/gun_detection/data/test_labels.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JiFlqNIEGcoO",
    "outputId": "90a3282c-c291-4987-8687-57f21cd43e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\n",
      "  ssd {\n",
      "    num_classes: 1\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      ssd_anchor_generator {\n",
      "        num_layers: 6\n",
      "        min_scale: 0.2\n",
      "        max_scale: 0.95\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        aspect_ratios: 3.0\n",
      "        aspect_ratios: 0.3333\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 300\n",
      "        width: 300\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      convolutional_box_predictor {\n",
      "        min_depth: 0\n",
      "        max_depth: 0\n",
      "        num_layers_before_predictor: 0\n",
      "        use_dropout: true\n",
      "        dropout_keep_probability: 0.8\n",
      "        kernel_size: 1\n",
      "        box_code_size: 4\n",
      "        apply_sigmoid_to_scores: false\n",
      "        conv_hyperparams {\n",
      "          activation: RELU_6,\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "            weight: 0.001\n",
      "          }\n",
      "          }\n",
      "          initializer {\n",
      "            truncated_normal_initializer {\n",
      "              stddev: 0.03\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "          batch_norm {\n",
      "            train: true,\n",
      "            scale: true,\n",
      "            center: true,\n",
      "            decay: 0.9997,\n",
      "            epsilon: 0.001,\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_mobilenet_v2'\n",
      "      min_depth: 16\n",
      "      depth_multiplier: 1.0\n",
      "      conv_hyperparams {\n",
      "        activation: RELU_6,\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.001\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          train: true,\n",
      "          scale: true,\n",
      "          center: true,\n",
      "          decay: 0.9997,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid {\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      hard_example_miner {\n",
      "        num_hard_examples: 3000\n",
      "        iou_threshold: 0.95\n",
      "        loss_type: CLASSIFICATION\n",
      "        max_negatives_per_positive: 3\n",
      "        min_negatives_per_image: 3\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 15\n",
      "        max_total_detections: 15\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 12\n",
      "  optimizer {\n",
      "    rms_prop_optimizer: {\n",
      "      learning_rate: {\n",
      "        exponential_decay_learning_rate {\n",
      "          initial_learning_rate: 0.003\n",
      "          decay_steps: 800720\n",
      "          decay_factor: 0.95\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "      decay: 0.9\n",
      "      epsilon: 1.0\n",
      "    }\n",
      "  }\n",
      "\n",
      "  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n",
      "  fine_tune_checkpoint_type:  \"detection\"\n",
      "  # Note: The below line limits the training process to 200K steps, which we\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\n",
      "  # never decay). Remove the below line to train indefinitely.\n",
      "  num_steps: 200000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_adjust_contrast {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    ssd_random_crop {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/gun_detection/data/train_labels.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  num_examples: 599\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
      "  # Remove the below line to evaluate indefinitely.\n",
      "  #max_evals: 10\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/gun_detection/data/test_labels.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_readers: 1\n",
      "}"
     ]
    }
   ],
   "source": [
    "#checking the config file after editing \n",
    "!cat {pipeline_fname} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuXXZLVEG8sO"
   },
   "outputs": [],
   "source": [
    "# where the model will be saved at each checkpoint while training \n",
    "model_dir = 'training/'\n",
    "\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_OnX4XnXo3U"
   },
   "outputs": [],
   "source": [
    "ls training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vAGvftxHu8K"
   },
   "source": [
    "## Tensorboard\n",
    "1. Downlaoding and unzipping Tensorboard\n",
    "2. creating a link to visualize multiple graph while training.\n",
    "\n",
    "\n",
    "notes: \n",
    "  1. Tensorboard will not log any files until the training starts. \n",
    "  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Z2ucxlc5HxHL",
    "outputId": "08e91468-9dd0-4df6-e8cd-9f72bd8378b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-05 01:55:22--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 52.71.210.177, 3.219.64.173, 34.197.213.11, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|52.71.210.177|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13773305 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.13M  14.2MB/s    in 0.9s    \n",
      "\n",
      "2019-12-05 01:55:23 (14.2 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "#downlaoding ngrok to be able to access tensorboard on google colab\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w9ufxr7IAdv"
   },
   "outputs": [],
   "source": [
    "#the logs that are created while training \n",
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "idsi9zyNIIsr",
    "outputId": "c847df07-ce6c-490e-d74d-c2b33997fb86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d8198d12.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "#The link to tensorboard. \n",
    "#works after the training starts.\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuJcAPZFIfu7"
   },
   "source": [
    "## Training\n",
    "\n",
    "Finally training the model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnKt6g0_IgOe"
   },
   "outputs": [],
   "source": [
    "\n",
    "!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={config_path + pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPN8liiQc7Ue"
   },
   "source": [
    "## Exporting The Trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upwUdom0lTub"
   },
   "outputs": [],
   "source": [
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNEJtfVqFQQz"
   },
   "outputs": [],
   "source": [
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qHvO4_6Fd5D"
   },
   "outputs": [],
   "source": [
    "!ls -alh {pb_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j283vkCUFeR7"
   },
   "outputs": [],
   "source": [
    "files.download(pb_fname)\n",
    "files.download(label_map_pbtxt_fname)\n",
    "files.download('/content/gun_detection/models/research/training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vgF4JdNt3Yy"
   },
   "source": [
    "## Finshing later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwqdHImEur-3"
   },
   "source": [
    "##### Inferecing and uploading a video directly from colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7j-BI_27X6nn"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(\"/content/gdrive/My Drive/weapon-tensorflow/training/label_map.pbtxt\")\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LrP2Dz4icok"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = '/content/gdrive/My Drive/weapon-tensorflow/data/images/test/small_img'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'armas ({}).jpg'.format(i)) for i in range(2915, 2925) ]\n",
    "IMAGE_SIZE = (12, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAy-Bdtoj8ml"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "4m76-M5Xitvs",
    "outputId": "d50fb701-edf2-4083-b3b4-00f9736c8edc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-530f9d5ef1b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# the array based representation of the image will be used later in order to prepare the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# result image with boxes and labels on it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_into_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Expand dimensions since the model expects images to have shape: [1, None, None, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimage_np_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_image_into_numpy_array' is not defined"
     ]
    }
   ],
   "source": [
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "            plt.figure(figsize=IMAGE_SIZE)\n",
    "            plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3W_C7-PBiXP8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExcyH--Vko_t"
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHz9mTank0aM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output returned should be a color image (3 channel) for processing video below\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            image_process = detect_objects(image, sess, detection_graph)\n",
    "            return image_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcfJvbuek0iL"
   },
   "outputs": [],
   "source": [
    "def detect_objects(image_np, sess, detection_graph):\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num_detections) = sess.run(\n",
    "        [boxes, scores, classes, num_detections],\n",
    "        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "xZdWEjXXl3tt",
    "outputId": "3cb830bf-b940-4d32-da17-8daa495159c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/gdrive/My Drive/weapon-tensorflow/models/research'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "RNgc3QLrk0pE",
    "outputId": "ecc69a06-23b2-486b-a27e-13c0df557aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video /content/gdrive/My Drive/weapon-tensorflow/sw_video_out.mp4\n",
      "[MoviePy] Writing video /content/gdrive/My Drive/weapon-tensorflow/sw_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665/665 [09:31<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: /content/gdrive/My Drive/weapon-tensorflow/sw_video_out.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "white_output = '/content/gdrive/My Drive/weapon-tensorflow/sw_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"/content/gdrive/My Drive/darknet/weapon/YOLOv3-Object-Detection-with-OpenCV-master/final.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!s\n",
    "white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IT9IfvKt9NL"
   },
   "source": [
    "##### Downlaod the inference directly from Youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAvqle9Ft65f"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YOUTUBE_ID = 'bQ53oTL2AzU'\n",
    "\n",
    "\n",
    "YouTubeVideo(YOUTUBE_ID)\n",
    "\n",
    "!rm -df youtube.mp4\n",
    "# download the youtube with the given ID\n",
    "!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
    "# do object detection only on the first 20 seconds...\n",
    "!ffmpeg -y -loglevel info -i youtube.mp4 -t 20 video.mp4\n",
    "\n",
    "video_capture = cv2.VideoCapture()\n",
    "if video_capture.open('video.mp4'):\n",
    "  width, height = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "  !rm -f output.mp4 output.avi\n",
    "  # can't write out mp4, so try to write into an AVI file\n",
    "  video_writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
    "  while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "      break\n",
    "      \n",
    "    start = time.time()\n",
    "    \n",
    "    rgb_frame = test(frame[:,:,::-1])\n",
    "    frame = rgb_frame[:,:,::-1]\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"time: {}s, fps: {}\".format(end-start, 1/(end-start)))\n",
    "            \n",
    "    video_writer.write(frame)\n",
    "  video_capture.release()\n",
    "  video_writer.release()\n",
    "  \n",
    "  # convert AVI to MP4\n",
    "  !ffmpeg -y -loglevel info -i output.avi output.mp4\n",
    "else:\n",
    "  print(\"can't open the given input video file!\")\n",
    "\n",
    "  \n",
    "def show_local_mp4_video(file_name, width=640, height=480):\n",
    "  import io\n",
    "  import base64\n",
    "  from IPython.display import HTML\n",
    "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
    "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
    "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
    "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
    "\n",
    "show_local_mp4_video('output.mp4', width=960, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jU4M6AwKuJbt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "swkbXzAAuOkm"
   },
   "source": [
    "##### Inferencing on unseen photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouXAeL3Zugkb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3GLmOs2uZrB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sOcbTFEiPBKA",
    "pOfuwfPrPSMz",
    "A_tyvKnBP6qD",
    "t9C3L_r4Pi6m",
    "xMckMSJqFMyc",
    "RPN8liiQc7Ue"
   ],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
